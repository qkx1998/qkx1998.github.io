{"meta":{"title":"slow dive","subtitle":null,"description":null,"author":"QKX","url":"http://yoursite.com","root":"/"},"pages":[],"posts":[{"title":"kaggle-York City Taxi Trip Duration","slug":"kaggle-York-City-Taxi-Trip-Duration","date":"2020-04-28T09:40:24.000Z","updated":"2020-04-28T10:40:03.548Z","comments":true,"path":"2020/04/28/kaggle-York-City-Taxi-Trip-Duration/","link":"","permalink":"http://yoursite.com/2020/04/28/kaggle-York-City-Taxi-Trip-Duration/","excerpt":"","text":"背景：预测纽约市出租车旅行的总行驶时间，数据集来源于纽约市出租车和豪华轿车委员会，其中包括上车时间，地理坐标，乘客人数以及其它几个变量。 1 理解赛题背景，赛题数据，评估指标。2 数据清洗，从缺失，重复值，数据分布等角度清洗数据。3 进行探索性数据分析。4 特征工程，从距离，方向，日期等角度新建特征。5 建模预测，利用gbdt,xgboost,lightgbm等进行模型融合。 思维导图： 数据清洗 12345678import pandas as pdimport numpy as npimport pyecharts as pefrom pyecharts import Bar,Line,Overlap,Gridfrom datetime import datetimetrain &#x3D; pd.read_csv(&#39;C:\\\\Users\\\\18438\\\\Desktop\\\\NYC_TAXI\\\\train.csv&#39;)test &#x3D; pd.read_csv(&#39;C:\\\\Users\\\\18438\\\\Desktop\\\\NYC_TAXI\\\\test.csv&#39;) 提取上车日期中的各种日期信息 123456train[&#39;year&#39;] &#x3D; pd.to_datetime(train[&#39;pickup_datetime&#39;]).dt.yeartrain[&#39;date&#39;] &#x3D; pd.to_datetime(train[&#39;pickup_datetime&#39;]).dt.datetrain[&#39;month&#39;] &#x3D; pd.to_datetime(train[&#39;pickup_datetime&#39;]).dt.monthtrain[&#39;weekday&#39;] &#x3D; pd.to_datetime(train[&#39;pickup_datetime&#39;]).dt.weekdaytrain[&#39;day&#39;] &#x3D; pd.to_datetime(train[&#39;pickup_datetime&#39;]).dt.daytrain[&#39;hour&#39;] &#x3D; pd.to_datetime(train[&#39;pickup_datetime&#39;]).dt.hour 去掉行驶时长数据异常值。观察数据存在异常的行驶时长，如1秒和980小时，所以在这里统一去掉偏离平均数两个标准差的数据。 1234m &#x3D; np.mean(train[&#39;trip_duration&#39;])s &#x3D; np.std(train[&#39;trip_duration&#39;])train &#x3D; train[train[&#39;trip_duration&#39;] &lt;&#x3D; m + 2*s]train &#x3D; train[train[&#39;trip_duration&#39;] &gt;&#x3D; m - 2*s] 去掉超过纽约边界的坐标数据 12345678910city_long_border &#x3D; (-74.03, -73.75)city_lat_border &#x3D; (40.63, 40.85) train &#x3D; train[train[&#39;pickup_longitude&#39;] &lt;&#x3D; -73.75]train &#x3D; train[train[&#39;pickup_longitude&#39;] &gt;&#x3D; -74.03]train &#x3D; train[train[&#39;pickup_latitude&#39;] &lt;&#x3D; 40.85]train &#x3D; train[train[&#39;pickup_latitude&#39;] &gt;&#x3D; 40.63]train &#x3D; train[train[&#39;dropoff_longitude&#39;] &lt;&#x3D; -73.75]train &#x3D; train[train[&#39;dropoff_longitude&#39;] &gt;&#x3D; -74.03]train &#x3D; train[train[&#39;dropoff_latitude&#39;] &lt;&#x3D; 40.85]train &#x3D; train[train[&#39;dropoff_latitude&#39;] &gt;&#x3D; 40.63] 探索性数据分析 1 观察不同时间段下的订单量的变化趋势（在分析中订单量认为可反映拥堵情况）2 观察不同时间段下的订单平均时间的变化趋势（在分析中平均时长认为可反映拥堵情况以及长途，短途单的比重）3 观察不同乘客数量 不同出租车公司以及关于store_and_fwd_flag特征的订单量变化4 对经纬度坐标进行Kmeans聚类，观察分布 对各个时间段下的订单量进行统计 123456789101112count_date &#x3D; train.groupby(&#39;date&#39;)[&#39;id&#39;].count().to_frame()count_month &#x3D; train.groupby(&#39;month&#39;)[&#39;id&#39;].count().to_frame()count_weekday &#x3D; train.groupby(&#39;weekday&#39;)[&#39;id&#39;].count().to_frame()count_day &#x3D; train.groupby(&#39;day&#39;)[&#39;id&#39;].count().to_frame()count_hour&#x3D; train.groupby(&#39;hour&#39;)[&#39;id&#39;].count().to_frame()line &#x3D; Line(&#39;订单数量变化趋势&#39;)line1 &#x3D; Line()line2 &#x3D; Line()line3 &#x3D; Line()line4 &#x3D; Line()line.add(&#39;天数&#39;,count_date.index,count_date[&#39;id&#39;]) 123456789line1.add(&#39;.&#39;,count_month.index,count_month[&#39;id&#39;])line2.add(&#39;.&#39;,count_day.index,count_day[&#39;id&#39;])line3.add(&#39;.&#39;,count_weekday.index,count_weekday[&#39;id&#39;])line4.add(&#39;.&#39;,count_hour.index,count_hour[&#39;id&#39;])grid &#x3D; Grid(height&#x3D;720, width&#x3D;1000)grid.add(line1, grid_bottom&#x3D;&quot;60%&quot;, grid_right&#x3D;&quot;60%&quot;)grid.add(line2,grid_bottom&#x3D;&quot;60%&quot;, grid_left&#x3D;&quot;60%&quot;)grid.add(line3,grid_top&#x3D;&quot;60%&quot;, grid_right&#x3D;&quot;60%&quot;)grid.add(line4,grid_top&#x3D;&quot;60%&quot;, grid_left&#x3D;&quot;60%&quot;) 对不同时间段下的订单平均时间的变化趋势进行分析。 123456789101112dtime_date &#x3D; train.groupby(&#39;date&#39;)[&#39;trip_duration&#39;].mean().to_frame()dtime_month &#x3D; train.groupby(&#39;month&#39;)[&#39;trip_duration&#39;].mean().to_frame()dtime_weekday &#x3D; train.groupby(&#39;weekday&#39;)[&#39;trip_duration&#39;].mean().to_frame()dtime_day &#x3D; train.groupby(&#39;day&#39;)[&#39;trip_duration&#39;].mean().to_frame()dtime_hour &#x3D; train.groupby(&#39;hour&#39;)[&#39;trip_duration&#39;].mean().to_frame()line5 &#x3D; Line(&#39;订单时间变化趋势&#39;)bar &#x3D; Bar()overlap &#x3D; Overlap()line5.add(&#39;柱状图&#39;,dtime_date.index,dtime_date[&#39;trip_duration&#39;])bar.add(&#39;折线图&#39;,dtime_date.index,dtime_date[&#39;trip_duration&#39;])overlap.add(line5)overlap.add(bar) 12345678910111213line6 &#x3D; Line()line7 &#x3D; Line()line8 &#x3D; Line()line9 &#x3D; Line()line6.add(&#39;.&#39;,dtime_month.index,dtime_month[&#39;trip_duration&#39;])line7.add(&#39;.&#39;,dtime_day.index,dtime_day[&#39;trip_duration&#39;])line8.add(&#39;.&#39;,dtime_weekday.index,dtime_weekday[&#39;trip_duration&#39;])line9.add(&#39;.&#39;,dtime_hour.index,dtime_hour[&#39;trip_duration&#39;])grid &#x3D; Grid(height&#x3D;720, width&#x3D;1000)grid.add(line6, grid_bottom&#x3D;&quot;60%&quot;, grid_right&#x3D;&quot;60%&quot;)grid.add(line7,grid_bottom&#x3D;&quot;60%&quot;, grid_left&#x3D;&quot;60%&quot;)grid.add(line8,grid_top&#x3D;&quot;60%&quot;, grid_right&#x3D;&quot;60%&quot;)grid.add(line9,grid_top&#x3D;&quot;60%&quot;, grid_left&#x3D;&quot;60%&quot;) 观察不同乘客数量 不同出租车公司以及关于store_and_fwd_flag特征的订单量变化 123456789pc_td &#x3D; train.groupby(&#39;passenger_count&#39;)[&#39;trip_duration&#39;].mean().to_frame()bar2 &#x3D; Bar(&#39;不同乘客数量的行程时长&#39;)bar2.add(&#39;人数&#39;,pc_td.index,pc_td[&#39;trip_duration&#39;])vi_td &#x3D; train.groupby(&#39;vendor_id&#39;)[&#39;trip_duration&#39;].mean().to_frame()bar3 &#x3D; Bar(&#39;不同出租车公司的行程时长&#39;)bar3.add(&#39;公司&#39;,vi_td.index,vi_td[&#39;trip_duration&#39;])saff_td &#x3D; train.groupby(&#39;store_and_fwd_flag&#39;)[&#39;trip_duration&#39;].mean().to_frame()bar4 &#x3D; Bar(&#39;有无store_and_fwd_flag的行程时长&#39;)bar4.add(&#39;有无store_and_fwd_flag&#39;,saff_td.index,saff_td[&#39;trip_duration&#39;]) 绘制上车点的位置 12345678910111213import matplotlib.pyplot as plt %matplotlib inlinecity_long_border &#x3D; (-74.03, -73.75)city_lat_border &#x3D; (40.63, 40.85)plt.scatter(train[&#39;pickup_longitude&#39;].values[:100000], train[&#39;pickup_latitude&#39;].values[:100000], color&#x3D;&#39;darkblue&#39;, s&#x3D;1, label&#x3D;&#39;train&#39;, alpha&#x3D;0.1)plt.legend(loc&#x3D;0)plt.ylabel(&#39;latitude&#39;)plt.xlabel(&#39;longitude&#39;)plt.ylim(city_lat_border)plt.xlim(city_long_border)plt.show() 绘制下车点的位置 1234567891011city_long_border &#x3D; (-74.03, -73.75)city_lat_border &#x3D; (40.63, 40.85)plt.scatter(train[&#39;dropoff_longitude&#39;].values[:100000], train[&#39;dropoff_latitude&#39;].values[:100000], color&#x3D;&#39;darkgreen&#39;, s&#x3D;1, label&#x3D;&#39;train&#39;, alpha&#x3D;0.1)plt.legend(loc&#x3D;0)plt.ylabel(&#39;latitude&#39;)plt.xlabel(&#39;longitude&#39;)plt.ylim(city_lat_border)plt.xlim(city_long_border)plt.show() 通过kmeans对曼哈顿区的上车下车区域进行聚类观察，可以更直观的理解数据。一共分三步：创建位置堆 1234567891011121314151617181920from sklearn.cluster import MiniBatchKMeanscoords &#x3D; np.vstack((train[[&#39;pickup_latitude&#39;, &#39;pickup_longitude&#39;]].values, train[[&#39;dropoff_latitude&#39;, &#39;dropoff_longitude&#39;]].values))sample_ind &#x3D; np.random.permutation(len(coords))[:500000]kmeans &#x3D; MiniBatchKMeans(n_clusters&#x3D;100, batch_size&#x3D;10000).fit(coords[sample_ind])train.loc[:, &#39;pickup_cluster&#39;] &#x3D; kmeans.predict(train[[&#39;pickup_latitude&#39;, &#39;pickup_longitude&#39;]])train.loc[:, &#39;dropoff_cluster&#39;] &#x3D; kmeans.predict(train[[&#39;dropoff_latitude&#39;, &#39;dropoff_longitude&#39;]])test.loc[:, &#39;pickup_cluster&#39;] &#x3D; kmeans.predict(test[[&#39;pickup_latitude&#39;, &#39;pickup_longitude&#39;]])test.loc[:, &#39;dropoff_cluster&#39;] &#x3D; kmeans.predict(test[[&#39;dropoff_latitude&#39;, &#39;dropoff_longitude&#39;]])plt.scatter(train.pickup_longitude.values[:500000], train.pickup_latitude.values[:500000], s&#x3D;10, lw&#x3D;0, c&#x3D;train.pickup_cluster[:500000].values, cmap&#x3D;&#39;autumn&#39;, alpha&#x3D;0.2)plt.xlim(city_long_border)plt.ylim(city_lat_border)plt.xlabel(&#39;Longitude&#39;)plt.ylabel(&#39;Latitude&#39;)plt.show() 特征工程 1.利用haversine计算两个经纬度点之间的距离 作为新特征2.利用两点之间直线距离公式（取对数）计算两个经纬度点之间的另一种距离表达 作为新特征3.是否为周末 作为新特征4.是否为假期 是否为假期前一天 作为新特征5.删除没用的信息6.独热编码 1234567891011121314151617181920212223def extract_features(df): #利用haversine计算两个经纬度点之间的距离 作为新特征 df[&#39;hdistance&#39;] &#x3D; df.apply(lambda r: haversine.haversine((r[&#39;pickup_latitude&#39;],r[&#39;pickup_longitude&#39;]),(r[&#39;dropoff_latitude&#39;], r[&#39;dropoff_longitude&#39;])), axis&#x3D;1) #利用两点之间直线距离公式计算两个经纬度点之间的另一种距离表达 作为新特征 df[&#39;distance&#39;] &#x3D; np.sqrt(np.power(df[&#39;dropoff_longitude&#39;] - df[&#39;pickup_longitude&#39;], 2) + np.power(df[&#39;dropoff_latitude&#39;] - df[&#39;pickup_latitude&#39;], 2)) #对上式求得的距离取对数 df[&#39;log_distance&#39;] &#x3D; np.log(df[&#39;distance&#39;] + 1) #判断是否是周末 df[&#39;is_weekend&#39;] &#x3D; ((df.pickup_datetime.astype(&#39;datetime64[ns]&#39;).dt.dayofweek) &#x2F;&#x2F; 4 &#x3D;&#x3D; 1).astype(float) #是否为 假期 把一些特定假期的日期通过lambda来筛选 是假期的为1 否则为0 df[&#39;is_holyday&#39;] &#x3D; df.apply(lambda row: 1 if (row[&#39;month&#39;]&#x3D;&#x3D;1 and row[&#39;day&#39;]&#x3D;&#x3D;1) or (row[&#39;month&#39;]&#x3D;&#x3D;7 and row[&#39;day&#39;]&#x3D;&#x3D;4) or (row[&#39;month&#39;]&#x3D;&#x3D;11 and row[&#39;day&#39;]&#x3D;&#x3D;11) or (row[&#39;month&#39;]&#x3D;&#x3D;12 and row[&#39;day&#39;]&#x3D;&#x3D;25) or (row[&#39;month&#39;]&#x3D;&#x3D;1 and row[&#39;day&#39;] &gt;&#x3D; 15 and row[&#39;day&#39;] &lt;&#x3D; 21 and row[&#39;weekday&#39;] &#x3D;&#x3D; 0) or (row[&#39;month&#39;]&#x3D;&#x3D;2 and row[&#39;day&#39;] &gt;&#x3D; 15 and row[&#39;day&#39;] &lt;&#x3D; 21 and row[&#39;weekday&#39;] &#x3D;&#x3D; 0) or (row[&#39;month&#39;]&#x3D;&#x3D;5 and row[&#39;day&#39;] &gt;&#x3D; 25 and row[&#39;day&#39;] &lt;&#x3D; 31 and row[&#39;weekday&#39;] &#x3D;&#x3D; 0) or (row[&#39;month&#39;]&#x3D;&#x3D;9 and row[&#39;day&#39;] &gt;&#x3D; 1 and row[&#39;day&#39;] &lt;&#x3D; 7 and row[&#39;weekday&#39;] &#x3D;&#x3D; 0) or (row[&#39;month&#39;]&#x3D;&#x3D;10 and row[&#39;day&#39;] &gt;&#x3D; 8 and row[&#39;day&#39;] &lt;&#x3D; 14 and row[&#39;weekday&#39;] &#x3D;&#x3D; 0) or (row[&#39;month&#39;]&#x3D;&#x3D;11 and row[&#39;day&#39;] &gt;&#x3D; 22 and row[&#39;day&#39;] &lt;&#x3D; 28 and row[&#39;weekday&#39;] &#x3D;&#x3D; 3) else 0, axis&#x3D;1) #是否为假期前一天 方法同上一步 df[&#39;is_day_before_holyday&#39;] &#x3D; df.apply(lambda row: 1 if (row[&#39;month&#39;]&#x3D;&#x3D;12 and row[&#39;day&#39;]&#x3D;&#x3D;31) or (row[&#39;month&#39;]&#x3D;&#x3D;7 and row[&#39;day&#39;]&#x3D;&#x3D;3) or (row[&#39;month&#39;]&#x3D;&#x3D;11 and row[&#39;day&#39;]&#x3D;&#x3D;10) or (row[&#39;month&#39;]&#x3D;&#x3D;12 and row[&#39;day&#39;]&#x3D;&#x3D;24) or (row[&#39;month&#39;]&#x3D;&#x3D;1 and row[&#39;day&#39;] &gt;&#x3D; 14 and row[&#39;day&#39;] &lt;&#x3D; 20 and row[&#39;weekday&#39;] &#x3D;&#x3D; 6) or (row[&#39;month&#39;]&#x3D;&#x3D;2 and row[&#39;day&#39;] &gt;&#x3D; 14 and row[&#39;day&#39;] &lt;&#x3D; 20 and row[&#39;weekday&#39;] &#x3D;&#x3D; 6) or (row[&#39;month&#39;]&#x3D;&#x3D;5 and row[&#39;day&#39;] &gt;&#x3D; 24 and row[&#39;day&#39;] &lt;&#x3D; 30 and row[&#39;weekday&#39;] &#x3D;&#x3D; 6) or ((row[&#39;month&#39;]&#x3D;&#x3D;9 and row[&#39;day&#39;] &gt;&#x3D; 1 and row[&#39;day&#39;] &lt;&#x3D; 6) or (row[&#39;month&#39;]&#x3D;&#x3D;8 and row[&#39;day&#39;] &#x3D;&#x3D; 31) and row[&#39;weekday&#39;] &#x3D;&#x3D; 6) or (row[&#39;month&#39;]&#x3D;&#x3D;10 and row[&#39;day&#39;] &gt;&#x3D; 7 and row[&#39;day&#39;] &lt;&#x3D; 13 and row[&#39;weekday&#39;] &#x3D;&#x3D; 6) or (row[&#39;month&#39;]&#x3D;&#x3D;11 and row[&#39;day&#39;] &gt;&#x3D; 21 and row[&#39;day&#39;] &lt;&#x3D; 27 and row[&#39;weekday&#39;] &#x3D;&#x3D; 2) else 0, axis&#x3D;1) df[&#39;store_and_fwd_flag&#39;] &#x3D; df[&#39;store_and_fwd_flag&#39;].map(lambda x: 0 if x &#x3D;&#x3D;&#39;N&#39; else 1)extract_features(train)extract_features(test) 123456789101112131415161718192021train &#x3D; train.drop([&#39;id&#39;,&#39;pickup_datetime&#39;,&#39;dropoff_datetime&#39;],axis&#x3D;1)test &#x3D; test.drop([&#39;id&#39;,&#39;pickup_datetime&#39;],axis&#x3D;1) train[&#39;trip_duration&#39;] &#x3D; np.log(train[&#39;trip_duration&#39;].values + 1)train &#x3D; pd.get_dummies(train)test &#x3D; pd.get_dummies(test)train &#x3D; pd.get_dummies(train)test &#x3D; pd.get_dummies(test)from sklearn.model_selection import train_test_splitTrain, Test &#x3D; train_test_split(train[0:100000], test_size &#x3D; 0.2)x_train &#x3D; Train.drop([&#39;trip_duration&#39;], axis&#x3D;1)y_train &#x3D; Train[&quot;trip_duration&quot;]x_val &#x3D; Test.drop([&#39;trip_duration&#39;], axis&#x3D;1)y_val &#x3D; Test[&quot;trip_duration&quot;]y_val &#x3D; y_val.reset_index().drop(&#39;index&#39;,axis &#x3D; 1)y_train &#x3D; y_train.reset_index().drop(&#39;index&#39;,axis &#x3D; 1)X_test &#x3D; test 建模预测 12345678import lightgbm as lgbimport xgboost as xgbfrom sklearn.model_selection import GridSearchCV,cross_val_scorefrom sklearn.ensemble import RandomForestRegressor,GradientBoostingRegressorfrom sklearn.model_selection import cross_val_score, train_test_splitfrom sklearn.metrics import mean_squared_error, mean_absolute_errorfrom sklearn import linear_modelfrom sklearn import preprocessing 12345678910111213141516171819202122232425262728293031def build_model_lr(x_train,y_train): reg_model &#x3D; linear_model.LinearRegression() reg_model.fit(x_train,y_train) return reg_modeldef build_model_gbdt(x_train,y_train): estimator &#x3D;GradientBoostingRegressor(loss&#x3D;&#39;ls&#39;,subsample&#x3D; 0.85,max_depth&#x3D; 5,n_estimators &#x3D; 100) param_grid &#x3D; &#123; &#39;learning_rate&#39;: [0.05,0.08,0.1,0.2], &#125; gbdt &#x3D; GridSearchCV(estimator, param_grid,cv&#x3D;3) gbdt.fit(x_train,y_train) print(gbdt.best_params_) # print(gbdt.best_estimator_ ) return gbdtdef build_model_xgb(x_train,y_train): model &#x3D; xgb.XGBRegressor(n_estimators&#x3D;120, learning_rate&#x3D;0.08, gamma&#x3D;0, subsample&#x3D;0.8,\\ colsample_bytree&#x3D;0.9, max_depth&#x3D;5) #, objective &#x3D;&#39;reg:squarederror&#39; model.fit(x_train, y_train) return modeldef build_model_lgb(x_train,y_train): estimator &#x3D; lgb.LGBMRegressor(num_leaves&#x3D;63,n_estimators &#x3D; 100) param_grid &#x3D; &#123; &#39;learning_rate&#39;: [0.01, 0.05, 0.1], &#125; gbm &#x3D; GridSearchCV(estimator, param_grid) gbm.fit(x_train, y_train) return gbm 1234567891011121314print(&#39;predict gbdt...&#39;)model_gbdt &#x3D; build_model_gbdt(x_train,y_train)val_gbdt &#x3D; model_gbdt.predict(x_val)subA_gbdt &#x3D; model_gbdt.predict(X_test)print(&#39;predict XGB...&#39;)model_xgb &#x3D; build_model_xgb(x_train,y_train)val_xgb &#x3D; model_xgb.predict(x_val)subA_xgb &#x3D; model_xgb.predict(X_test)print(&#39;predict lgb...&#39;)model_lgb &#x3D; build_model_lgb(x_train,y_train)val_lgb &#x3D; model_lgb.predict(x_val)subA_lgb &#x3D; model_lgb.predict(X_test) 12345678910111213141516171819202122232425262728293031323334353637# Stacking## 第一层train_lgb_pred &#x3D; model_lgb.predict(x_train)train_xgb_pred &#x3D; model_xgb.predict(x_train)train_gbdt_pred &#x3D; model_gbdt.predict(x_train)Strak_X_train &#x3D; pd.DataFrame()Strak_X_train[&#39;Method_1&#39;] &#x3D; train_lgb_predStrak_X_train[&#39;Method_2&#39;] &#x3D; train_xgb_predStrak_X_train[&#39;Method_3&#39;] &#x3D; train_gbdt_predStrak_X_val &#x3D; pd.DataFrame()Strak_X_val[&#39;Method_1&#39;] &#x3D; val_lgbStrak_X_val[&#39;Method_2&#39;] &#x3D; val_xgbStrak_X_val[&#39;Method_3&#39;] &#x3D; val_gbdtStrak_X_test &#x3D; pd.DataFrame()Strak_X_test[&#39;Method_1&#39;] &#x3D; subA_lgbStrak_X_test[&#39;Method_2&#39;] &#x3D; subA_xgbStrak_X_test[&#39;Method_3&#39;] &#x3D; subA_gbdt## level2-method model_lr_Stacking &#x3D; build_model_lr(Strak_X_train,y_train)## 训练集train_pre_Stacking &#x3D; model_lr_Stacking.predict(Strak_X_train)print(&#39;RMSE of Stacking-LR:&#39;,sqrt(mean_squared_error(y_train,train_pre_Stacking)))## 验证集val_pre_Stacking &#x3D; model_lr_Stacking.predict(Strak_X_val)print(&#39;RMSE of Stacking-LR:&#39;,sqrt(mean_squared_error(y_val,val_pre_Stacking)))## 预测集print(&#39;Predict Stacking-LR...&#39;)subA_Stacking &#x3D; model_lr_Stacking.predict(Strak_X_test) 生成预测 123456sub &#x3D; pd.DataFrame()Test_data &#x3D; pd.read_csv(&#39;C:\\\\Users\\\\18438\\\\Desktop\\\\NYC_TAXI\\\\test.csv&#39;, sep&#x3D;&#39;,&#39;)sub[&#39;id&#39;] &#x3D; Test_data[&#39;id&#39;]sub[&#39;trip_duration&#39;] &#x3D; subA_Stackingsub.to_csv(&#39;C:\\\\Users\\\\18438\\\\Desktop\\\\NYC_TAXI\\\\sub_Stacking.csv&#39;,index&#x3D;False)","categories":[],"tags":[]},{"title":"天池-二手车交易价格预测","slug":"天池-二手车交易价格预测","date":"2020-04-25T12:45:32.000Z","updated":"2020-04-25T12:45:32.340Z","comments":true,"path":"2020/04/25/天池-二手车交易价格预测/","link":"","permalink":"http://yoursite.com/2020/04/25/%E5%A4%A9%E6%B1%A0-%E4%BA%8C%E6%89%8B%E8%BD%A6%E4%BA%A4%E6%98%93%E4%BB%B7%E6%A0%BC%E9%A2%84%E6%B5%8B/","excerpt":"","text":"","categories":[],"tags":[]}],"categories":[],"tags":[]}